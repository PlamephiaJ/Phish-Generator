<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Installation &#8212; Phish-Generator 0.0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=b08954a9" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=27fed22d" />
    <script src="../_static/documentation_options.js?v=d45e8c67"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Quickstart: BERT Pre-trained Model Fine-tuning on WAF Dataset" href="quickstart.html" />
    <link rel="prev" title="Data synthesis Research Project" href="../index.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="installation">
<h1>Installation<a class="headerlink" href="#installation" title="Link to this heading">¶</a></h1>
<section id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p><strong>Python</strong>: Version &gt;= 3.9</p></li>
<li><p><strong>CUDA</strong>: Version &gt;= 12.4</p></li>
</ul>
</section>
<section id="install-from-docker-image">
<h2>Install from Docker Image<a class="headerlink" href="#install-from-docker-image" title="Link to this heading">¶</a></h2>
<p>This feature is coming soon. Stay tuned for updates on Docker image availability.</p>
</section>
<section id="install-from-custom-environment">
<h2>Install from Custom Environment<a class="headerlink" href="#install-from-custom-environment" title="Link to this heading">¶</a></h2>
<p>We recommend using Docker images for convenience. However, if your environment is not compatible with the Docker image, you can install <cite>smf</cite> in a Python environment.</p>
</section>
</section>
<section id="pre-requisites">
<h1>Pre-requisites<a class="headerlink" href="#pre-requisites" title="Link to this heading">¶</a></h1>
<p>To ensure a smooth installation of <cite>smf</cite>, you need to set up the necessary CUDA and cuDNN dependencies. These are critical for leveraging GPU acceleration in <cite>smf</cite>’s operations.</p>
<p>We need to install the following pre-requisites:</p>
<ul class="simple">
<li><p><strong>CUDA</strong>: Version &gt;= 12.4</p></li>
<li><p><strong>cuDNN</strong>: Version &gt;= 9.8.0</p></li>
</ul>
<p>CUDA version 12.4 or higher is recommended to align with the Docker image. For other CUDA versions, refer to <a class="reference external" href="https://developer.nvidia.com/cuda-toolkit-archive">NVIDIA CUDA website</a>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Change directory to a location of your choice; avoid the smf source code directory</span>
wget<span class="w"> </span>https://developer.download.nvidia.com/compute/cuda/12.4.1/local_installers/cuda-repo-ubuntu2204-12-4-local_12.4.1-550.54.15-1_amd64.deb
dpkg<span class="w"> </span>-i<span class="w"> </span>cuda-repo-ubuntu2204-12-4-local_12.4.1-550.54.15-1_amd64.deb
cp<span class="w"> </span>/var/cuda-repo-ubuntu2204-12-4-local/cuda-*-keyring.gpg<span class="w"> </span>/usr/share/keyrings/
apt-get<span class="w"> </span>update
apt-get<span class="w"> </span>-y<span class="w"> </span>install<span class="w"> </span>cuda-toolkit-12-4
update-alternatives<span class="w"> </span>--set<span class="w"> </span>cuda<span class="w"> </span>/usr/local/cuda-12.4
</pre></div>
</div>
<p>cuDNN can be installed using the following commands. For other cuDNN versions, refer to <a class="reference external" href="https://developer.nvidia.com/rdp/cudnn-archive">NVIDIA cuDNN website</a>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Change directory to a location of your choice; avoid the smf source code directory</span>
wget<span class="w"> </span>https://developer.download.nvidia.com/compute/cudnn/9.8.0/local_installers/cudnn-local-repo-ubuntu2204-9.8.0_1.0-1_amd64.deb
dpkg<span class="w"> </span>-i<span class="w"> </span>cudnn-local-repo-ubuntu2204-9.8.0_1.0-1_amd64.deb
cp<span class="w"> </span>/var/cudnn-local-repo-ubuntu2204-9.8.0/cudnn-*-keyring.gpg<span class="w"> </span>/usr/share/keyrings/
apt-get<span class="w"> </span>update
apt-get<span class="w"> </span>-y<span class="w"> </span>install<span class="w"> </span>cudnn-cuda-12
</pre></div>
</div>
</section>
<section id="install-dependencies">
<h1>Install Dependencies<a class="headerlink" href="#install-dependencies" title="Link to this heading">¶</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We recommend using a fresh Conda environment to install <cite>smf</cite> and its dependencies to avoid conflicts.</p>
<p><strong>Warning</strong>: Inference frameworks like vLLM may override your installed PyTorch version if not carefully managed. To prevent this, install inference frameworks first with their required PyTorch version. If you want to use an existing PyTorch installation with vLLM, follow their official instructions at <a class="reference external" href="https://docs.vllm.ai/en/latest/getting_started/installation/gpu.html#build-wheel-from-source">Use an existing PyTorch installation</a>.</p>
</div>
<ol class="arabic simple">
<li><p>First, set up a Conda environment with Python 3.10:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>create<span class="w"> </span>-n<span class="w"> </span>smf_env<span class="w"> </span><span class="nv">python</span><span class="o">=</span><span class="m">3</span>.10
conda<span class="w"> </span>activate<span class="w"> </span>smf_env
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Next, execute the <code class="docutils literal notranslate"><span class="pre">install.sh</span></code> script provided in the <cite>smf</cite> repository to install dependencies:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ensure the smf_env Conda environment is activated</span>
bash<span class="w"> </span>install.sh
</pre></div>
</div>
<p>If you encounter errors during this step, inspect the <code class="docutils literal notranslate"><span class="pre">install.sh</span></code> script and manually execute the steps outlined within it.</p>
<section id="install-smf">
<h2>Install smf<a class="headerlink" href="#install-smf" title="Link to this heading">¶</a></h2>
<p>To install the latest version of <cite>smf</cite>, clone the repository and install it from source. This approach allows you to modify the code to customize post-training jobs.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://rnd-gitlab-ca-g.huawei.com/vanpub/ai_firewall.git
<span class="nb">cd</span><span class="w"> </span>ai_firewall
pip<span class="w"> </span>install<span class="w"> </span>--no-deps<span class="w"> </span>-e<span class="w"> </span>.
</pre></div>
</div>
</section>
</section>
<section id="post-installation">
<h1>Post-installation<a class="headerlink" href="#post-installation" title="Link to this heading">¶</a></h1>
<p>After installation, verify that the installed packages have not been overridden by other installations. Pay particular attention to the following packages:</p>
<ul class="simple">
<li><p><strong>torch</strong> and related torch packages</p></li>
<li><p><strong>nvidia-cudnn-cu12</strong>: Required for the Magetron backend</p></li>
</ul>
<p>To check the installed versions, you can use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>list<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-E<span class="w"> </span><span class="s1">&#39;torch|nvidia-cudnn-cu12&#39;</span>
</pre></div>
</div>
<p>If any discrepancies are found, reinstall the affected packages to ensure compatibility with <cite>smf</cite>.</p>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Phish-Generator</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">GETTING STARTED</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#requirements">Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="#install-from-docker-image">Install from Docker Image</a></li>
<li class="toctree-l2"><a class="reference internal" href="#install-from-custom-environment">Install from Custom Environment</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#pre-requisites">Pre-requisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="#install-dependencies">Install Dependencies</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#install-smf">Install smf</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#post-installation">Post-installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart: BERT Pre-trained Model Fine-tuning on WAF Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="codestyle.html">codestyle</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="../index.html" title="previous chapter">Data synthesis Research Project</a></li>
      <li>Next: <a href="quickstart.html" title="next chapter">Quickstart: BERT Pre-trained Model Fine-tuning on WAF Dataset</a></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2025, CNLab_Victoria.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.2.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="../_sources/start/install.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>